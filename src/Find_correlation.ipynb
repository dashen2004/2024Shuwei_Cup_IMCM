{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data from CSV files\n",
    "data1 = pd.read_csv('F1_collaborative_variable1.csv')\n",
    "data2 = pd.read_csv('F1_collaborative_variable2.csv')\n",
    "data3 = pd.read_csv('F1_collaborative_variable3.csv')\n",
    "data4 = pd.read_csv('F1_collaborative_variable4.csv')\n",
    "target_data = pd.read_csv('F1_target_variable.csv')\n",
    "\n",
    "# Extract the target property column from each dataset\n",
    "data1 = data1['Target Property']\n",
    "data2 = data2['Target Property']\n",
    "data3 = data3['Target Property']\n",
    "data4 = data4['Target Property']\n",
    "target_data = target_data['Target Property']\n",
    "\n",
    "# --------------------------\n",
    "# Data Preprocessing\n",
    "# --------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Initialize StandardScaler and MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Standardize the data\n",
    "data1_standardized = scaler.fit_transform(data1.values.reshape(-1, 1))\n",
    "data2_standardized = scaler.fit_transform(data2.values.reshape(-1, 1))\n",
    "data3_standardized = scaler.fit_transform(data3.values.reshape(-1, 1))\n",
    "data4_standardized = scaler.fit_transform(data4.values.reshape(-1, 1))\n",
    "target_data_standardized = scaler.fit_transform(target_data.values.reshape(-1, 1))\n",
    "\n",
    "# Normalize the standardized data\n",
    "data1_normalized = min_max_scaler.fit_transform(data1_standardized)\n",
    "data2_normalized = min_max_scaler.fit_transform(data2_standardized)\n",
    "data3_normalized = min_max_scaler.fit_transform(data3_standardized)\n",
    "data4_normalized = min_max_scaler.fit_transform(data4_standardized)\n",
    "target_data_normalized = min_max_scaler.fit_transform(target_data_standardized)\n",
    "\n",
    "# --------------------------\n",
    "# Pearson Correlation Coefficients\n",
    "# --------------------------\n",
    "\n",
    "# Compute the correlation between each variable and the target variable (using standardized data)\n",
    "correlation1 = np.corrcoef(data1_standardized.flatten(), target_data_standardized.flatten())[0, 1]\n",
    "correlation2 = np.corrcoef(data2_standardized.flatten(), target_data_standardized.flatten())[0, 1]\n",
    "correlation3 = np.corrcoef(data3_standardized.flatten(), target_data_standardized.flatten())[0, 1]\n",
    "correlation4 = np.corrcoef(data4_standardized.flatten(), target_data_standardized.flatten())[0, 1]\n",
    "\n",
    "# Print the correlation results\n",
    "print(f'Correlation between Variable 1 and Target: {correlation1}')\n",
    "print(f'Correlation between Variable 2 and Target: {correlation2}')\n",
    "print(f'Correlation between Variable 3 and Target: {correlation3}')\n",
    "print(f'Correlation between Variable 4 and Target: {correlation4}')\n",
    "\n",
    "# Compute the correlation on the original data (without normalization/standardization)\n",
    "correlation1_raw = np.corrcoef(data1, target_data)[0, 1]\n",
    "correlation2_raw = np.corrcoef(data2, target_data)[0, 1]\n",
    "correlation3_raw = np.corrcoef(data3, target_data)[0, 1]\n",
    "correlation4_raw = np.corrcoef(data4, target_data)[0, 1]\n",
    "\n",
    "# Print the raw data correlation results\n",
    "print(f'\\nRaw data correlation between Variable 1 and Target: {correlation1_raw}')\n",
    "print(f'Raw data correlation between Variable 2 and Target: {correlation2_raw}')\n",
    "print(f'Raw data correlation between Variable 3 and Target: {correlation3_raw}')\n",
    "print(f'Raw data correlation between Variable 4 and Target: {correlation4_raw}')\n",
    "\n",
    "# --------------------------\n",
    "# QQ-Plot (Normality Check)\n",
    "# --------------------------\n",
    "\n",
    "# Generate QQ plots for each variable to check if the data follows a normal distribution\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# QQ plot for Variable 1\n",
    "stats.probplot(data1_standardized.flatten(), dist=\"norm\", plot=axs[0, 0])\n",
    "axs[0, 0].set_title('QQ Plot of Variable 1')\n",
    "\n",
    "# QQ plot for Variable 2\n",
    "stats.probplot(data2_standardized.flatten(), dist=\"norm\", plot=axs[0, 1])\n",
    "axs[0, 1].set_title('QQ Plot of Variable 2')\n",
    "\n",
    "# QQ plot for Variable 3\n",
    "stats.probplot(data3_standardized.flatten(), dist=\"norm\", plot=axs[1, 0])\n",
    "axs[1, 0].set_title('QQ Plot of Variable 3')\n",
    "\n",
    "# QQ plot for Variable 4\n",
    "stats.probplot(data4_standardized.flatten(), dist=\"norm\", plot=axs[1, 1])\n",
    "axs[1, 1].set_title('QQ Plot of Variable 4')\n",
    "\n",
    "# Save and show the QQ plot\n",
    "plt.savefig('QQ Plot.png')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Pearson and Spearman Correlation Coefficients (Final)\n",
    "# --------------------------\n",
    "\n",
    "# Compute Pearson correlation coefficients for each variable and target (after standardization)\n",
    "pearson_corr1 = np.corrcoef(data1_standardized.flatten(), target_data_standardized.flatten())[0, 1]\n",
    "pearson_corr2 = np.corrcoef(data2_standardized.flatten(), target_data_standardized.flatten())[0, 1]\n",
    "pearson_corr3 = np.corrcoef(data3_standardized.flatten(), target_data_standardized.flatten())[0, 1]\n",
    "pearson_corr4 = np.corrcoef(data4_standardized.flatten(), target_data_standardized.flatten())[0, 1]\n",
    "\n",
    "# Print Pearson correlation results\n",
    "print(f'Pearson correlation between Variable 1 and Target: {pearson_corr1}')\n",
    "print(f'Pearson correlation between Variable 2 and Target: {pearson_corr2}')\n",
    "print(f'Pearson correlation between Variable 3 and Target: {pearson_corr3}')\n",
    "print(f'Pearson correlation between Variable 4 and Target: {pearson_corr4}')\n",
    "\n",
    "# Compute Spearman correlation coefficients\n",
    "spearman_corr1 = stats.spearmanr(data1_standardized.flatten(), target_data_standardized.flatten())[0]\n",
    "spearman_corr2 = stats.spearmanr(data2_standardized.flatten(), target_data_standardized.flatten())[0]\n",
    "spearman_corr3 = stats.spearmanr(data3_standardized.flatten(), target_data_standardized.flatten())[0]\n",
    "spearman_corr4 = stats.spearmanr(data4_standardized.flatten(), target_data_standardized.flatten())[0]\n",
    "\n",
    "# Print Spearman correlation results\n",
    "print(f'\\nSpearman correlation between Variable 1 and Target: {spearman_corr1}')\n",
    "print(f'Spearman correlation between Variable 2 and Target: {spearman_corr2}')\n",
    "print(f'Spearman correlation between Variable 3 and Target: {spearman_corr3}')\n",
    "print(f'Spearman correlation between Variable 4 and Target: {spearman_corr4}')\n",
    "\n",
    "# --------------------------\n",
    "# Hexbin Plots (Correlation Visualization)\n",
    "# --------------------------\n",
    "\n",
    "# Create a 2x2 subplot for hexbin plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Hexbin plot for Variable 1 vs Target\n",
    "hb1 = axs[0, 0].hexbin(data1, target_data, gridsize=50, cmap='Blues')\n",
    "axs[0, 0].set_title(f'Variable 1 vs Target (Spearman Correlation: {spearman_corr1:.2f})')\n",
    "axs[0, 0].set_xlabel('Variable 1')\n",
    "axs[0, 0].set_ylabel('Target')\n",
    "fig.colorbar(hb1, ax=axs[0, 0], label='Count')\n",
    "\n",
    "# Hexbin plot for Variable 2 vs Target\n",
    "hb2 = axs[0, 1].hexbin(data2, target_data, gridsize=50, cmap='Blues')\n",
    "axs[0, 1].set_title(f'Variable 2 vs Target (Spearman Correlation: {spearman_corr2:.2f})')\n",
    "axs[0, 1].set_xlabel('Variable 2')\n",
    "axs[0, 1].set_ylabel('Target')\n",
    "fig.colorbar(hb2, ax=axs[0, 1], label='Count')\n",
    "\n",
    "# Hexbin plot for Variable 3 vs Target\n",
    "hb3 = axs[1, 0].hexbin(data3, target_data, gridsize=50, cmap='Blues')\n",
    "axs[1, 0].set_title(f'Variable 3 vs Target (Spearman Correlation: {spearman_corr3:.2f})')\n",
    "axs[1, 0].set_xlabel('Variable 3')\n",
    "axs[1, 0].set_ylabel('Target')\n",
    "fig.colorbar(hb3, ax=axs[1, 0], label='Count')\n",
    "\n",
    "# Hexbin plot for Variable 4 vs Target\n",
    "hb4 = axs[1, 1].hexbin(data4, target_data, gridsize=50, cmap='Blues')\n",
    "axs[1, 1].set_title(f'Variable 4 vs Target (Spearman Correlation: {spearman_corr4:.2f})')\n",
    "axs[1, 1].set_xlabel('Variable 4')\n",
    "axs[1, 1].set_ylabel('Target')\n",
    "fig.colorbar(hb4, ax=axs[1, 1], label='Count')\n",
    "\n",
    "# Save and show the Hexbin plot\n",
    "plt.savefig('Hexagonal Bin Plot.png')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
